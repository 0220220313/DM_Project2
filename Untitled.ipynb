{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_attributes=['hp','atk','ap','ad','md','speed','rank']\n",
    "card_value=np.random.rand(100000,7)\n",
    "card_value[:,6]=0\n",
    "weight_value=[4000,1000,1000,600,600,700,2000,500,500,400,400,300]\n",
    "for i in range(6):\n",
    "    card_value[:,i]*=weight_value[i]\n",
    "    card_value[:,i]+=weight_value[i+6]\n",
    "for i in range(len(card_value)):\n",
    "    if(card_value[i,1]+card_value[i,2]>2000):\n",
    "        if(card_value[i,1]>card_value[i,2]):\n",
    "            card_value[i,2]=1500-card_value[i,1]\n",
    "        else:\n",
    "            card_value[i,1]=1500-card_value[i,2]\n",
    "card_value=np.rint(card_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1666     0.524      1.03375    0.60117647]\n",
      " [0.5278     1.0368     0.55       0.81882353]\n",
      " [0.9074     0.8624     0.631875   0.56352941]]\n",
      "1.0 43576\n",
      "2.0 66719\n",
      "3.0 85605\n",
      "4.0 93606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nrank_value=card_value[:,0]*0.2+ (card_value[:,1]+card_value[:,2])*0.4 + abs(card_value[:,1]-card_value[:,2])*0.2\\nprint(rank_value[0:6])\\n\\nrank_value=rank_value+(card_value[:,3]+card_value[:,4])*0.6+card_value[:,5]*1.2 + abs(card_value[:,3]-card_value[:,4])*0.3\\nprint(rank_value[0:6])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_value=np.zeros((len(card_value),4),dtype=np.double)\n",
    "card_value[:,6]=0\n",
    "compare=[5000,1250,1600,850]\n",
    "for i in range(len(card_value)):\n",
    "    tmp=[];\n",
    "    tmp=[card_value[i,0],max(card_value[i,1],card_value[i,2]),card_value[i,3]+card_value[i,4],card_value[i,5]]\n",
    "    for j in range(4):\n",
    "        rank_value[i][j]=tmp[j]/compare[j]\n",
    "print(rank_value[1:10][0:3])\n",
    "rank=[1,0.9,0.8]\n",
    "ss=0\n",
    "for i in range(len(card_value)):\n",
    "    for j in range(3):\n",
    "        if rank_value[i,0]>rank[j] and rank_value[i,2]>rank[j] :\n",
    "            card_value[i,6]=3-j\n",
    "            if (rank_value[i,1]>rank[j] or rank_value[i,3]>rank[j])and card_value[i,6]==3:\n",
    "                card_value[i,6]+=1\n",
    "            break\n",
    "        if rank_value[i,1]>rank[j] and rank_value[i,3]>rank[j] :\n",
    "            card_value[i,6]=3-j\n",
    "            if (rank_value[i,0]>rank[j] or rank_value[i,2]>rank[j]) and card_value[i,6]==3:\n",
    "                card_value[i,6]+=1\n",
    "            break\n",
    "dis=[]\n",
    "dis=card_value[:,6]\n",
    "dis=np.sort(dis)\n",
    "now=0\n",
    "ids=0\n",
    "for i in range (len(card_value)):\n",
    "    if(dis[i]!=now):\n",
    "        now=dis[i]\n",
    "        print(now,i)\n",
    "        \n",
    "        \n",
    "            \n",
    "'''\n",
    "rank_value=card_value[:,0]*0.2+ (card_value[:,1]+card_value[:,2])*0.4 + abs(card_value[:,1]-card_value[:,2])*0.2\n",
    "print(rank_value[0:6])\n",
    "\n",
    "rank_value=rank_value+(card_value[:,3]+card_value[:,4])*0.6+card_value[:,5]*1.2 + abs(card_value[:,3]-card_value[:,4])*0.3\n",
    "print(rank_value[0:6])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSrank_value=sorted(rank_value)\\nL=len(Srank_value)\\nrule=[Srank_value[int(0.2*L)],Srank_value[int(0.4*L)],Srank_value[int(0.6*L)],Srank_value[int(L*0.8)]]\\n#rule=[Srank_value[int(L*0.5)]]\\nprint(rule)\\nfor i in range (10000):\\n    if rank_value[i]>=rule[3]:\\n           card_value[i,6]=4\\n    elif rank_value[i]>=rule[2]:\\n        card_value[i,6]=3\\n    elif rank_value[i]>=rule[1]:\\n        card_value[i,6]=2\\n    elif rank_value[i]>=rule[0]:\\n        card_value[i,6]=1\\n    else :\\n        card_value[i,6]=0\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Srank_value=sorted(rank_value)\n",
    "L=len(Srank_value)\n",
    "rule=[Srank_value[int(0.2*L)],Srank_value[int(0.4*L)],Srank_value[int(0.6*L)],Srank_value[int(L*0.8)]]\n",
    "#rule=[Srank_value[int(L*0.5)]]\n",
    "print(rule)\n",
    "for i in range (10000):\n",
    "    if rank_value[i]>=rule[3]:\n",
    "           card_value[i,6]=4\n",
    "    elif rank_value[i]>=rule[2]:\n",
    "        card_value[i,6]=3\n",
    "    elif rank_value[i]>=rule[1]:\n",
    "        card_value[i,6]=2\n",
    "    elif rank_value[i]>=rule[0]:\n",
    "        card_value[i,6]=1\n",
    "    else :\n",
    "        card_value[i,6]=0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame(card_value,columns=card_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['hp','atk','ap','ad','md','speed']], data[['rank']], test_size=0.3, random_state=0) \n",
    "\n",
    "#'hp','atk','ap','def','apd','speed'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.95 %\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'entropy', random_state=0,max_depth=4)  #max_depth=3\n",
    "tree.fit(X_train,y_train)\n",
    "error = 0\n",
    "for i, v in enumerate(tree.predict(X_test)):\n",
    "    if v!= y_test['rank'].values[i]:\n",
    "        #print(i,v)\n",
    "        error+=1\n",
    "print(100-error*100/len(X_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(tree, out_file='tree.dot', feature_names=['hp','atk','ap','ad','md','speed'])\n",
    "#'hp','atk','ap','def','apd','speed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion='entropy', n_estimators=10,random_state=3,n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=8,\n",
       "            oob_score=False, random_state=3, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train,y_train['rank'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.57 %\n"
     ]
    }
   ],
   "source": [
    "forest.score(X_test,y_test['rank'])\n",
    "error=0\n",
    "result=forest.predict(X_test)\n",
    "for i in range(len(y_test)):\n",
    "    if result[i]!=y_test['rank'].values[i]:\n",
    "        error+=1\n",
    "print(100-100*error/len(y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegressionCV #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.123333333333335 %\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegressionCV()\n",
    "lr.fit(X_train,y_train)\n",
    "lr.score(X_test,y_test)\n",
    "\n",
    "error=0\n",
    "result=lr.predict(X_test)\n",
    "for i in range(len(y_test)):\n",
    "    if result[i]!=y_test['rank'].values[i]:\n",
    "        error+=1\n",
    "print(100-100*error/len(y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knn=KNeighborsClassifier(n_neighbors=3)\n",
    "Knn.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8344333333333334"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.44333333333333 %\n"
     ]
    }
   ],
   "source": [
    "error=0\n",
    "result=Knn.predict(X_test)\n",
    "for i in range(len(y_test)):\n",
    "    if result[i]!=y_test['rank'].values[i]:\n",
    "        error+=1\n",
    "print(100-100*error/len(y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ANN   #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten ,LSTM\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding  \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 216)               1512      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 216)               46872     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 216)               46872     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 216)               46872     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 216)               46872     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 1085      \n",
      "=================================================================\n",
      "Total params: 190,085\n",
      "Trainable params: 190,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Dropout(0.2, input_shape=(6,)))\n",
    "model.add(Dense(units=36*6,input_dim=6,activation='relu'))\n",
    "model.add(Dense(units=36*6,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=36*6,activation='relu'))\n",
    "model.add(Dense(units=36*6,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=36*6,activation='relu'))\n",
    "model.add(Dense(units=5,activation='softmax'))\n",
    "model.summary()\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD\n",
    "opt = optimizers.SGD(lr=0.01, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = opt,metrics=['accuracy'])\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train) \n",
    "Y_test = np_utils.to_categorical(y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nss=StandardScaler()\\nss2=ss.fit(X_test)\\nX_test=ss2.transform(X_test)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss=StandardScaler()\n",
    "ss2=ss.fit(X_train)\n",
    "X_train=ss2.transform(X_train)\n",
    "'''\n",
    "ss=StandardScaler()\n",
    "ss2=ss.fit(X_test)\n",
    "X_test=ss2.transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56000 samples, validate on 14000 samples\n",
      "Epoch 1/30\n",
      "56000/56000 [==============================] - 6s 101us/step - loss: 0.6722 - acc: 0.7129 - val_loss: 0.2654 - val_acc: 0.8978\n",
      "Epoch 2/30\n",
      "56000/56000 [==============================] - 5s 90us/step - loss: 0.2830 - acc: 0.8818 - val_loss: 0.1913 - val_acc: 0.9217\n",
      "Epoch 3/30\n",
      "56000/56000 [==============================] - 5s 90us/step - loss: 0.2234 - acc: 0.9046 - val_loss: 0.1602 - val_acc: 0.9291\n",
      "Epoch 4/30\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.1965 - acc: 0.9178 - val_loss: 0.1351 - val_acc: 0.9469\n",
      "Epoch 5/30\n",
      "56000/56000 [==============================] - 5s 96us/step - loss: 0.1815 - acc: 0.9236 - val_loss: 0.1271 - val_acc: 0.9459\n",
      "Epoch 6/30\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.1697 - acc: 0.9290 - val_loss: 0.1197 - val_acc: 0.9481\n",
      "Epoch 7/30\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.1613 - acc: 0.9320 - val_loss: 0.1222 - val_acc: 0.9454\n",
      "Epoch 8/30\n",
      "56000/56000 [==============================] - 5s 95us/step - loss: 0.1471 - acc: 0.9382 - val_loss: 0.1137 - val_acc: 0.9529\n",
      "Epoch 9/30\n",
      "56000/56000 [==============================] - 5s 90us/step - loss: 0.1447 - acc: 0.9385 - val_loss: 0.1064 - val_acc: 0.9554\n",
      "Epoch 10/30\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.1361 - acc: 0.9427 - val_loss: 0.0931 - val_acc: 0.9619\n",
      "Epoch 11/30\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.1312 - acc: 0.9450 - val_loss: 0.1058 - val_acc: 0.9553\n",
      "Epoch 12/30\n",
      "56000/56000 [==============================] - 5s 94us/step - loss: 0.1250 - acc: 0.9481 - val_loss: 0.0903 - val_acc: 0.9624\n",
      "Epoch 13/30\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.1218 - acc: 0.9490 - val_loss: 0.0830 - val_acc: 0.9656\n",
      "Epoch 14/30\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.1186 - acc: 0.9511 - val_loss: 0.0959 - val_acc: 0.9604\n",
      "Epoch 15/30\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.1131 - acc: 0.9523 - val_loss: 0.0815 - val_acc: 0.9669\n",
      "Epoch 16/30\n",
      "56000/56000 [==============================] - 5s 93us/step - loss: 0.1128 - acc: 0.9530 - val_loss: 0.0853 - val_acc: 0.9646\n",
      "Epoch 17/30\n",
      "56000/56000 [==============================] - 5s 93us/step - loss: 0.1092 - acc: 0.9548 - val_loss: 0.0854 - val_acc: 0.9640\n",
      "Epoch 18/30\n",
      "56000/56000 [==============================] - 5s 96us/step - loss: 0.1069 - acc: 0.9544 - val_loss: 0.0822 - val_acc: 0.9643\n",
      "Epoch 19/30\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.1053 - acc: 0.9567 - val_loss: 0.0726 - val_acc: 0.9708\n",
      "Epoch 20/30\n",
      "56000/56000 [==============================] - 5s 91us/step - loss: 0.1016 - acc: 0.9573 - val_loss: 0.0763 - val_acc: 0.9686\n",
      "Epoch 21/30\n",
      "56000/56000 [==============================] - 5s 91us/step - loss: 0.0989 - acc: 0.9595 - val_loss: 0.0712 - val_acc: 0.9699\n",
      "Epoch 22/30\n",
      "56000/56000 [==============================] - 5s 91us/step - loss: 0.0965 - acc: 0.9598 - val_loss: 0.0788 - val_acc: 0.9664\n",
      "Epoch 23/30\n",
      "56000/56000 [==============================] - 5s 91us/step - loss: 0.0948 - acc: 0.9602 - val_loss: 0.0723 - val_acc: 0.9714\n",
      "Epoch 24/30\n",
      "56000/56000 [==============================] - 5s 89us/step - loss: 0.0937 - acc: 0.9615 - val_loss: 0.0731 - val_acc: 0.9689\n",
      "Epoch 25/30\n",
      "56000/56000 [==============================] - 5s 96us/step - loss: 0.0930 - acc: 0.9613 - val_loss: 0.0821 - val_acc: 0.9649\n",
      "Epoch 26/30\n",
      "56000/56000 [==============================] - 5s 92us/step - loss: 0.0888 - acc: 0.9638 - val_loss: 0.0665 - val_acc: 0.9734\n",
      "Epoch 27/30\n",
      "56000/56000 [==============================] - 5s 96us/step - loss: 0.0879 - acc: 0.9644 - val_loss: 0.0738 - val_acc: 0.9699\n",
      "Epoch 28/30\n",
      "56000/56000 [==============================] - 5s 97us/step - loss: 0.0845 - acc: 0.9649 - val_loss: 0.0717 - val_acc: 0.9684\n",
      "Epoch 29/30\n",
      "56000/56000 [==============================] - 5s 95us/step - loss: 0.0845 - acc: 0.9653 - val_loss: 0.0854 - val_acc: 0.9637\n",
      "Epoch 30/30\n",
      "56000/56000 [==============================] - 5s 97us/step - loss: 0.0828 - acc: 0.9661 - val_loss: 0.0693 - val_acc: 0.9699\n"
     ]
    }
   ],
   "source": [
    "ANN= model.fit(x=X_train, y=Y_train, validation_split=0.2,epochs=30,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 2s 77us/step\n",
      "0.9339333333333333\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,Y_test)\n",
    "print(1-score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
